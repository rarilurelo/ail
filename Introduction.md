## 原田先生
機械学習を使って画像分類,認識をしている人.
画像の特徴ベクトルとテキストの特徴ベクトル.その共起を考え,損失関数を計算し,最小化する.
2012年2位CNNに負けた.
2015年5位くらい.

## 先端人工知能論1
### 機械学習とは
+ pattern recognitionのいち分野
+ マシンに明示的に分類規則を与えない
+ 学習を行う


#### 分類と回帰
出力変数が連続の時回帰.離散の場合分類.
独立変数の個数.

#### 機械学習の種類
教師あり学習,教師なし学習,強化学習,(半教師あり学習)
をやる

#### 分類問題のパイプライン  
入力$\to$特徴抽出$\to$識別$\to$カテゴリ

#### 特徴抽出
特徴ベクトルが得られるよ.
+ 線の傾き
+ 長さ
+ 曲率

とかを使う.

特徴ベクトルによって張られる空間Feature Space  
１つのパターンはd次元の特徴空間の一点として表される.

#### 決定領域・決定境界
特徴空間のパーティションを行い,その空間にラベルを貼る.


#### 識別器の作り方
学習データ: 対応するクラスが与えられている小数のパターン(全部でない)  
予測対象となるデータ: 対応クラスがあたっているか判別
汎化性能: 学習データ以外にどのくらいの精度か

#### 最近傍法
##### アルゴリズム
距離関数をテストデータと学習データでとる.距離を最小にするものをラベルにする.

距離の定義は色々ある.
+ ユークリッド距離
+ マハラノビス距離
+ マンハッタン距離

###### 問題点
近いのがどこか,一番近いところでいいの？
$\to$
k近傍法

入力パターンのうち上位ｋつの近いやつとってきて多数決する.

長所
+ 単純
+ 学習パターンが少なくても安定

短所
+ 距離関数の取り方がわからない
+ 学習データが増えると計算コストが高い

計算コストを下げるために代表点を見つけ,その垂直二等分線で決定領域を考える.

実際の決定領域が線形分離可能でない時,代表点をいくつかとらないといけない.  
線形で分離$\to$線形識別器  
複数の線形識別器$\to$区分的線形識別器

最近傍法は区分線形識別器  
中間層のユニット数と代表点の数が対応.極限的には

kを増やすにつれてkがなめらかになる.

### 教師あり学習の評価方法
識別器はPositiveかNegativeで分類.  
それがあっているかいないかで４つのクラス  
精度(Precision): $\frac{TP}{TP+FP}$  
再現率(Recall): $\frac{TP}{TP+FN}$  
F値(F-measure): $\frac{2Recall*Precision}{Recall+Precision}$  
正解率(Accuracy): $\frac{TP+TN}{TP+FP+FN+TN}$

#### 過学習
モデル選択によって予測誤差を最小化する.  
交叉検証法: 学習データを分割して各々の学習とその誤差を求め,平均しそれが最小となるようにハイパーパラメータを決める.



